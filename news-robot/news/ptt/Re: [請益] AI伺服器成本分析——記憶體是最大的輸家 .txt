作者deepdish (Keep The Faith)看板Stock標題Re: [請益] AI伺服器成本分析——記憶體是最大的輸家時間Tue May 30 01:06:07 2023
覺得大家好像都看錯重點吧

以前伺服器需要大量記憶體

是因為要維持即時服務非常多人的需求

就像 PTT 可以有十萬人一起上站嘛

如果無法做到

就很像是被 DDOS 攻擊

網站就連不上惹

但一到深夜 PTT 根本沒啥活人在線上惹

然後現在是資料爆量的時代

譬如以抖音來說

甚至可以用 AI 去做人臉的影像分析

人臉影像分析可以在伺服器內部做的

那根本不需要做到即時分析

伺服器有空閒餘裕的時候再做就好

所以成本可以降低沒錯阿
※ 引述《mooto (退出會比較好, 就退出)》之銘言：
: ※ 引述《neone (neone)》之銘言：
: : 剛看到半導體產業分析機構semianalysis的這篇新文章:
: : https://www.semianalysis.com/p/ai-server-cost-analysis-memory-is
: : 雖然沒付費只能看到部分
: : bing摘要:
: : 這篇文章的核心內容是分析人工智能伺服器的成本。文章指出，隨著數據中心建設的瘋狂
: : ，市場也隨之瘋狂。但是，有許多公司並不應該因此而受益。文章還提到，IT預算有限，
: : 因此Nvidia銷售額的增長主要來自於購買較少的非GPU伺服器。文章中還提供了一個標準
: : CPU伺服器的成本分解，顯示內存佔伺服器成本的近40%。文章最後指出，在人工智能時代
: : ，普通伺服器的百分比將會下降，並且在數據中心轉向加速計算時，各組件的成本分配也
: : 會發生重大變化。
: 老黃今天展示的那櫃 Grace Hooper
: 就用了144TB GPU Memory 透過NVLink共享
: (NVLink是他們自研的SERDES
:  簡單來說就是PCIe更快的介面)
: 所以重點只是高速 共享
: 記憶體還是存在的
: 還有也不用擔心大家嫌貴不買啦
: 老黃今天不就列了1600家要做AI的公司
: 挖不挖得到金礦又不關他的事
: 只要鏟子賣得出去就好了
: 這種時候大家都爭搶先當第一個啦
: 有機會變成AI界的m$, adobe誰不幹
: 在那邊省小錢 到時候就看別人鼠錢
: 反正新創花的也不是自己錢
: 燒光當然是再繼續吹
: 話說老黃真的值得領那個錢
: 美國人訓練不是蓋的
: 相比之下今天下午發哥找他來蹭
: 那些高層講話的台風  投影片的格局 真的差好多喔

→ yunf        : 你也只講到了一種層面的狀況 05/30 01:24

噓 Severine    : https://i.imgur.com/kZPsq82.png 05/30 01:48

噓 qwe78971    : 感覺你是文組的 05/30 01:50

噓 momvic110456: 喔 05/30 01:56

噓 cyshowen    : 記憶體最好會變輸家啦，需求是越來越高 05/30 02:00

→ foxbrush    : 你知道你在說門外漢的話嗎？ 05/30 02:10

噓 qq251988    : 可憐啊 菜成這樣為什麼敢發言 05/30 02:18

→ fakejoker   : 是我太菜所以不懂你想表達什麼嗎... 05/30 04:36

噓 darkangel119: 如果只是單方面思考單層問題 伺服器不是這樣運作 05/30 04:48

推 lu19900217  : 現在顯卡的記憶體越來越多好嘛，尤其牽扯算力，記憶 05/30 06:51

→ lu19900217  : 體越大越好，ai最好記憶體會少用 05/30 06:51

→ timTan      : 看不懂 05/30 07:02

噓 DB2         : 外行的拜託不要亂發文 05/30 07:33

→ WarIII      : 顯卡如果不吃記憶體 為什麼顯存也越來越大？ 05/30 07:55

→ Kobe5210    : 新手就潛水就好 05/30 08:09

噓 k85564      : ？ 05/30 08:28

噓 kinki999    : 這ID不就AI 最大用戶，連回答也是 05/30 08:43

推 mqhung      : 找AI來回答，可能會好一點。 05/30 08:51

噓 shhs1000246 : 你到底在講啥 05/30 08:59

噓 QDR18       : ... 05/30 09:11

噓 ohsexygirl  : 講這麼多，怎不問GPT 05/30 09:15

噓 EDhsiao     : 那你這種神邏輯，那麼散熱也可以減少，成本可以變 05/30 09:18

→ EDhsiao     : 更低，反正伺服器有空再做運算就不燙了 05/30 09:18

噓 Xyla        : 哩咧公殺小？？？ 05/30 09:27

噓 justdoit    : 聽君一席話 05/30 09:38

推 lucky017110 : 顯卡顯存大應該現在遊戲畫面太精緻圖像處理太多要預 05/30 09:49

→ lucky017110 : 先載入顯卡記憶體中供GPU處理吧，不然容易卡頓讀畫 05/30 09:49

→ lucky017110 : 面 05/30 09:49

噓 b0117       : 這種程度也趕回這文 05/30 10:28

噓 andysher    : 我是覺得外行就不要硬要發文丟臉啦 05/30 10:56

→ owennice    : 你的主修是不是小喇叭 05/30 12:11

噓 zip00000    : 這神邏輯是有顆cpu或gpu其他都不用是吧？ 05/30 14:04

噓 catboost    : 你這回答是GPT教你討噓的嗎 05/30 14:23

→ eemail      : 尖峰跟離峰問題....你扯到什麼去了@@ 05/30 16:58
