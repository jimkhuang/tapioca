作者TreeMan (好啊...)看板Stock標題Re: [新聞] 馬斯克等千人簽署公開信：呼籲暫停巨型AI時間Wed Mar 29 21:28:12 2023

公開信的原文：
https://futureoflife.org/open-letter/pause-giant-ai-experiments/

它裡面提到4個自我省思，其中第1點：假訊息

是曾經/正在發生，而且造成實質損失



人類判讀訊息真實性時，經驗/直覺可以在新證據 (假設是新聞、訊息) 不多、不強

或物理上不可能時，達到足夠的判斷效果

而證據的重要組成：影像、聲音、來源數

目前生成式模型已經可以很有力的產生人類無法輕易辨識的資料

以前人工時代較容易有破綻，數量也不夠多

現在就是看誰算力夠，就有機會產生足量且高品質的假資料

做為其惡性地宣傳地證據



如果時間夠長，平均來說還是可以判斷真假

然而對於反應時間短，有機會造成損失預期的假證據

平均來說不會完全相信，但會進行某種程度的防禦措施，避免損害

特別是做了也無損失的情況

例如2018年的衛生紙事件

看到新聞的人想著下班先買個衛生紙放著

然後看見彼此購買的行為又強化了缺少的感覺

最後就可以成真到某個時間點



而當生成式AI足夠優秀的時候 (也許future of life預期可能是近年)

具有足夠算力的組織或人

可以大量、多樣化的高品質假證據時

就可以透過網路媒體 (傳統媒體為了避免落後也會盡快跟上)

快速地傳給許多人

再透過經實驗確認過的真實帳號之反應狀況

來評估滾雪球的狀態

並早一步布局較有可能的成真的項目，從中獲利



假想某個上市公司A的賺錢方式是用衛生紙做蓮花來賣

然後有個邪惡組織有規劃的短時間發佈 多張不同超市 缺衛生紙的照片

搭配一些小短片 透過合成人臉和聲音 告訴你真的缺衛生紙啦

因為衛生紙遭到大量搶購 (缺原料)

上市公司A就沒蓮花衛生紙可賣，邪惡組織就空爆他

或是趁他緊張 (時間壓力) 高價賣他衛生紙



整個過程就像高級的詐騙簡訊一樣

只是詐騙簡訊是廣發後，屬於易受騙的族群 (假設2.5%) 會中招

現在因為假證據升級了

邪惡組織可以透過"平均來說"的反應 進行後續規劃

當然邪惡組織也有可能因為人類的非線性反應受損

比如說衛生紙都被囤光了 他因為知道這是假消息 所以沒有多買

結果這組織就買不到 只好拿錢擦屁股 或去買更貴的衛生紙




另外是法律面

它也比詐騙簡訊更高級了

因為你不是造成收訊者的損失

是造成收訊者反應後 某個倒楣鬼的損失

你也沒有直接從倒楣鬼那邊偷搶拐騙錢

而是依據他損失的反應而正當獲利

這直覺很難...從法律去有效的制裁



承上，Future of Life Institute提出的應對方向是甚麼呢？

生產設備可追朔：...oversight and tracking of highly capable AI systems and
large pools of computational capability...

AI浮水印(類似基改標籤)：...provenance and watermarking systems to help
distinguish real from synthetic and to track model leaks

AI傷害的責任歸屬 (法律)...liability for AI-caused harm...

金援確保AI安全的研究...robust public funding for technical AI safety
research...

建構應對AI危害的組織 (AI管理局？) ...well-resourced institutions for
coping with the dramatic economic and political disruptions
(especially to democracy) that AI will cause...


一直以來都有針對生成式模型的辨識模型研究

但短期應該打不贏，因為生成式AI才吸睛又吸金

用AI去辨識誰是AI，避免災害，比較像公共安全

而且技術上應該也很難 如果這樣防衛模型是可買到的

就可以用它加入生成模型的訓練

當然這樣也可以增加生成式AI的成本就是



至於他們提到的6個月，感覺有點謎



股點...

如果有在開發浮水印類技術或符合前述目標的公司

應該可以投資看看 至少符合他們明面上的目標吧



噓 nidhogg     : 論點很奇怪 03/29 21:29

推 jimmihg     : 以目前AI成長的速度,很快就會有AI生成Musk的影像跟 03/29 21:36

→ jimmihg     : 聲音,而且會是極難辨識的情況 03/29 21:37

→ jimmihg     : 這也是Sam Altman推出chatGPT的原因,監管必須盡快 03/29 21:38

→ jimmihg     : 現在的政府根本不知道AI成長的速度有多快 03/29 21:38

推 aimlin      : 不用監管 進步才快 03/29 21:44

推 abccbaandy  : 同1F...這個哪需要AI，看我們不就是這樣，媒體各種 03/29 21:46

→ abccbaandy  : 嘴砲，人民也隨便相信 03/29 21:46

推 aimlin      : 等ai畫a片 03/29 21:47

推 chaoliu     : 沒錯啊 黑道詐騙僱幾個碼農作假app 假網站博弈就賺 03/29 21:52

→ chaoliu     : 翻了 AI工具他們能拿來怎麼騙 你想想就發毛 開源是 03/29 21:52

→ chaoliu     : 錯誤的 絕不能開源 馬斯克這點是錯的 AI交給微軟這 03/29 21:53

推 linkmusic   : 就是以前雇網軍作的事,現在靠AI就能更大量帶風向了 03/29 21:53

→ chaoliu     : 種有信譽的公司安排才是對的 03/29 21:53

→ shliau      : AI買股當沖期貨程式 03/29 22:06

推 s900527     : 微軟有信譽？哪一個宇宙的微軟 03/29 22:11

推 gibbs1286   : 最後就是AI對抗AI 03/29 22:13

推 wts4832     : AI發展阻擋不了的，最後只能用AI對抗AI，結論就是快 03/29 22:17

→ wts4832     : 買AI股票發大財 03/29 22:17

→ nwoyao      : 還不是人為的假訊息害的 笑死 03/29 22:25

→ codotsun    : 笑死 這樣不就共產極權才會做的事 03/29 22:27

→ codotsun    : 我沒辦法控制 所以全部ban掉就好 03/29 22:27

推 clairehao   : 第一個論點就很奇怪 ai更進步反而假訊息判斷會更強 03/29 22:32

→ clairehao   : 吧 雖然假訊息也會變種 但科技不就是這樣要發展改善 03/29 22:32

→ clairehao   : 下去嗎 03/29 22:32

推 boringuy    : 你可以反向思考，利用AI過濾大量訊息分辨假訊息 03/29 22:36

→ boringuy    : 還可以抓出源頭在那，科技只是工具怎麼利用的是人 03/29 22:37

推 zaqimon     : AI生成影像聲音已經都有了吧 03/29 22:43

→ zaqimon     : https://youtu.be/17_xLsqny9E 03/29 22:43

→ zaqimon     : 可惜AI還沒學會炒股賺大錢 03/29 22:45

→ zaqimon     : 不然很快世界首富應該都會變成AI才對 03/29 22:46

→ zaqimon     : 還是比爾蓋茲巴菲特那些人其實都是AI 03/29 22:47

→ hnjsh       : 看看本站的第一大版列車發車的次數，時代在進步，群 03/29 22:52

→ hnjsh       : 眾分辨假消息的能力卻越來越差了 03/29 22:52

推 lavign      : 以後line上聊天你媽也不一定是你媽 可能是AI 03/29 23:08

推 vicklin     : 簡單來說就是利用AI的犯罪效率快要高到沒辦法防了 03/29 23:11

推 lavign      : 生成式zero day attack人類是擋不住的 03/29 23:13

推 part19      : 掌握資訊的就贏 中間的往下沉 弱勢的永遠不得翻身 03/29 23:28

→ opencat     : 跑不贏別人  只好鼓譟暫停比賽 :D 03/29 23:39

推 sd785       : 歐盟已經開始討論針對AI立法了 可見疑慮真的很大 03/30 00:21

噓 HenryLin123 : 噓項目 03/30 01:07

噓 deepdish    : 大公司都偷偷用多久AI惹 不要找一堆藉口阻礙時代進 03/30 05:15

噓 deepdish    : https://youtu.be/sPvv8S7W0ww 03/30 05:42

→ deepdish    : 懼怕AI? 審查困難...日經曝中國禁止科技巨頭提供Cha 03/30 05:42

→ deepdish    : 4,520 views  Feb 23, 2023  #大世界 #三立iNEWS 03/30 05:42

推 honglu587654: 說到假訊息，如果是擠兌的假訊息，會不會造成恐慌？ 03/30 06:02

→ honglu587654: 畢竟現在把錢賺走也是在手機動動手指就能完成的事 03/30 06:03

→ honglu587654: *轉 03/30 06:04

噓 bleedwolf   : 保守派思維，30年前：別看電視, 20年前：別上網，10 03/30 08:39

→ bleedwolf   : 年前：別用智慧手機，現在：我們要禁止AI, 事實就是 03/30 08:39

→ bleedwolf   : ，你永遠檔不住科技的進步，只能趕快跟上然後學會應 03/30 08:39

→ bleedwolf   : 用 03/30 08:39

推 fancydick501: 事實 但不需要停下來 03/30 08:40

→ SkyShih     : 你講的不說AI,我還以為是台灣黨媒 03/30 09:31

推 seemoon2000 : 說實話 現在ai的進步速度 6個月可以讓落後很多的大 03/30 09:58

→ seemoon2000 : 幅追上 只有落後方會接受這種條件 要監管倒是沒話 03/30 09:58

→ seemoon2000 : 說 03/30 09:58

推 acgotaku    : 現在技術無法判別資訊的正確性的情況下 03/30 11:31

→ acgotaku    : 只能對所有在網路上的文字 圖影 保持不可信的態度 03/30 11:32

噓 miyazakisun2: 用Ai對付ai 03/30 12:31

→ miyazakisun2: 孤狗口罩的布來源  幾秒鐘就破解留言了 問題就是沒 03/30 12:32

→ miyazakisun2: 查證的習慣 03/30 12:32

→ miyazakisun2: 硬要短時間衝來衝去搞高風險 然後怪環境 怪科技 03/30 12:33

推 AdventurerCC: Deep fake 的危險性吧，我覺得確實有必要先考量 03/30 14:25

噓 weitin7011  : 神經病 你自己可以做別人不行就是 03/30 18:44

噓 quartics    : AI進展太快，立法跟不上，一定是衍生一堆問題，加 03/30 19:57

→ quartics    : 上會大量失業，雖然技術造成生產力大幅提升，但結 03/30 19:57

→ quartics    : 果不見得就真的造福大多數人 03/30 19:57
