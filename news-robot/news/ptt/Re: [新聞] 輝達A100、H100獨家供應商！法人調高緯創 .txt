作者LDPC (Channel Coding)看板Stock標題Re: [新聞] 輝達A100、H100獨家供應商！法人調高緯創時間Wed Jul  5 03:09:32 2023
前陣子自家公司GPU也不夠用了...在測試一堆想法時候 決定自掏腰包去租外面GPU
找了幾間像是 https://lambdalabs.com/ 結果...wtf 也是大爆滿
看了幾個AI論壇 一堆自行開發者都自己測試各種pretrained model的下游fine-tune
也是各種哀嚎搶GPU 以前這幫個人開發者在自己的RTX 就可以簡單測試 但現在的
LLaMA也好 Diffusion也好 越來越難在家用遊戲顯卡上跑

尤其這陣子流行Foundation Model 每個小測試GPU都要xN (N>16) 這種方式去train
對比幾年前一兩個GPU就能搞出點東西的時代過去了 現在就是萬物暴力解
CLIP這種東西甚至資料都高達數個TB 以後二線公司沒足夠GPU就是別想玩大模型設計
Pretrain/Foundation Model 全部只能做下游adapter 然後第三方或個人開發者
就可以拿這些fine-tune model 去設計自己需求 各種AI落地方案開始遍佈

然後這種大模型就是造就GPU極度缺乏!!!! 最近找遍各種第三方GPU租用計算之後
以及在內部公司 隨便丟個大模型測試 都要在自家公司上server排隊個三四天才能跑
第三方租用 我已經等了一個禮拜 根本排不到 甚至看了一下討論串 感覺一堆矽谷各公司
都在屯GPU https://shorturl.at/ouwMS https://udn.com/news/story/6811/7199315

上週的感覺真讓我想起2020 我那時候為了買個家俱 要等上半年以上..於是默默地
就繼續加碼三大股的其中兩個

如果蘇媽MI-300真的好用話 會一定分流 不過現階段H-100的優勢就是有Transformer
加速優勢(據說三倍加速以上) 而MI-300沒這優勢 尤其現在AI架構都是萬物Transformer
這波就是Transformer/Foundation Model+硬體暴力解 搭配Fine-Tune搞起AI流
(有興趣可以看FeiFei Li 那幫人對Foundation Model的預測和見解
https://arxiv.org/abs/2108.07258) 順帶一提Qualcomm這波完全選擇AI光譜的另一端
他們選走on-device路線 就是大模型對立面 大模型和on-device可以說是AI極大和極小
概念 看起來華爾街這幫人對on-device題材 完全不感興趣

老黃當年第一個提出GPU概念 從2000~2010 跟ATI每六個月增加硬體效能
互相硬體效能瘋狂對決 軍備競賽 帶動3D遊戲市場 感覺歷史又再一次循環...
https://www.youtube.com/watch?v=BlI9PVQA8ZA

然後以後人類的用途就是去當電池了QQ 這波AI繼續搞下去 以後一定缺電

推 cuteSquirrel: 推編碼哥 07/05 03:16

→ Sugimoto5566: 推編碼哥 07/05 03:27

→ yangyy2     : 改用浸沒式水冷可以大幅節電,阿里巴巴的資料中心很 07/05 03:52

→ yangyy2     : 早之前就用浸沒水冷了 07/05 03:52

噓 winner0429  : AI大氾濫時代 一堆參差不齊的公司寫一些垃圾AI來浪 07/05 03:58

→ winner0429  : 費電的 07/05 03:58

推 henry122822 : 推 07/05 04:00

推 d9936679    : 讚 07/05 04:02

→ musie       : 這波不會一直下去 1. LORA等新技術壓縮 07/05 04:11

→ musie       : 2.資料品質遠重於數量: Textbook is all you need 07/05 04:12

→ musie       : 3.Autoregressive LLM有其極限在.很快大家就發現 07/05 04:13

→ musie       : 怎麼fine tune 都修東壞西.. 07/05 04:14

→ musie       : 差不多一年就會緩和了 除非有新的架構出現 07/05 04:15

推 aresa       : 新概念永遠是brute force的，接下來肯定會出現個神 07/05 05:01

→ aresa       : 經病提出一個很優美的算法然後直接被寫進課本供著 07/05 05:01

→ ichitakajoe : 跟挖礦消耗顯卡差多了吧 07/05 05:27

→ ichitakajoe : ABF的需求好像也是喊到2030？ 07/05 05:27

噓 a000000000  : 尼今天發電幾瓦 07/05 06:19

→ ichitakajoe : 教主來惹 07/05 06:25

推 strlen      : 嗯...這個有點AI泡沫的味兒惹 這群中咖小咖瘋搶GPU 07/05 06:28

→ strlen      : 但最後一個一個就像煙火一樣爆完就 啪 沒惹 然後又 07/05 06:28

→ strlen      : 爽到老黃 07/05 06:28

推 poru        : AI就算力較強的晶片，這本來在晶片技術演進上就早 07/05 06:38

→ poru        : 晚的事，只是把他灌個AI附加價值就高出一般晶片好 07/05 06:38

→ poru        : 幾倍，根本是提早吃未來老本 07/05 06:38

→ poru        : 下次在遇到經濟不景氣，不就要改推出super 級AI來 07/05 06:40

→ poru        : 拯救 07/05 06:40

推 poisonB     : 推 業內 07/05 06:52

推 Chilloutt   : 當電池或當人造人 07/05 07:00

推 AndyMAX     : 遲早的事 一堆人不相信 07/05 07:15

推 ppuuppu     : 推 07/05 07:40

→ come        : 輝達明明就是跟美超微合作的，不知道緯創在漲什麼 07/05 07:54

推 create8     : 幹，要變電池惹，工程師有優待嗎QQ 07/05 08:06

推 littenVenus : 謝謝分享～ 07/05 08:09

→ hydra7      : 我電池我驕傲~ 07/05 08:15

推 saygogo     : 母豬教主報到 07/05 08:41

推 deepelves   : 輝達跟超微合作這是老黃要跟蘇媽一起發大財嗎? 07/05 09:53

→ LDPC        : 樓樓上是說Supermicro超微才不是AMD的超微 07/05 09:58

→ appledick   : AI論壇不是在流行跑在APPLE的晶片上了，便宜又大碗 07/05 10:08

→ appledick   : 散熱又好 07/05 10:08

推 csluling    : 看到deepelves的推文，今天早上心情都好了～ 07/05 10:13

推 ctttttt     : 推你 推極客灣 07/05 10:14

推 davidaustin : 人肉電池 07/05 10:36

推 aegis43210  : 某些超肥大的LLM適合跑在m2ultra，但仍不是主流，因 07/05 14:04

→ aegis43210  : 為nvlink可以把A100用到640G 07/05 14:04

→ Alwen       : 老黃的好東西有些只給企業級用戶 07/05 14:35

→ Alwen       : 個人玩家自己也training不出什麼有用的大殺器 07/05 14:36

推 MiniArse    : 除了訓練大模型必備的H100/A100 這波也會帶動 RTX40 07/05 14:53

→ MiniArse    : 系列在個人電腦上跑 stable diffusion 之類的應用 07/05 14:54

→ MiniArse    : 根據之前某創業家的描述，模型還真的是愈大 效果愈 07/05 14:55

→ MiniArse    : 愈好 尤其CUDA發展超過10年 MI很難在短時間追上 07/05 14:56

推 blue7896    : 歐印AMD,NVDA,SMCI 07/05 17:05
