傳Naver成立AI安全性中心
2024-01-04
近期由於國際社會對「人工智慧（AI）安全性」的疑慮增加，傳出Naver成立直屬於執行長（CEO）崔秀姸的AI安全性組織，專門研究AI安全性問題，欲同時發展AI技術與提高AI安全性。
據韓媒首爾經濟報導，2024年1月1日Naver進行組織結構調整，新設「未來AI中心」（Future AI Center），負責全球AI研究與制訂AI政策，期望透過AI安全性研究進行更有責任感的AI研發。
面對國際社會對AI安全性與可靠度的質疑，檢討是否應有相關規範的聲浪之中，Naver成立未來AI中心加以應對。據了解，未來AI中心人員編制約100名，由Naver Cloud AI創新中心主任河正祐（音譯）擔任負責人。
未來AI中心將從事提高AI安全性的技術研究，並且制訂Naver的AI倫理政策，使自家的大規模語言模型（LLM）HyperCLOVA X開發出更安全的服務，減少管理風險，建置具有安全性的超大規模AI生態圈。此外，未來AI中心有意與國內外研究機構合作，共同成立研究中心，研發AI安全性技術。
2021年Naver已與德國蒂賓根大學（University of Tübingen）簽署「研發安全與信賴的AI合作協議」，目前也與加拿大多倫多大學（University of Toronto）合作進行AI研究。
Naver表示，國際社會對AI技術與AI的安全性十分重視，為了推動AI事業進軍國際市場，2024年將「AI安全性」作為重要發展目標。2024年1月5日將南韓與英國合辦「AI安全性高峰會議」，未來會有更多南韓科技業者從事與AI安全性有關的研究，推動安全、可靠的治理機制。
責任編輯：毛履兆
