{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import requests\n",
    "import sqlite3\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animal():\n",
    "    def __init__(self, vars ,**kwargs):\n",
    "        self.__dict__.update(vars, **kwargs)\n",
    "\n",
    "class crawl(Animal):\n",
    "\n",
    "    def ptt(self, url):\n",
    "        header = self.__dict__\n",
    "        r = requests.get(url, headers=header)\n",
    "\n",
    "        if r.status_code == 200:\n",
    "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "       \n",
    "            web_list = []\n",
    "            for i in soup.find_all(\"div\", class_='r-ent'):\n",
    "                j = i.find_all(\"a\", href=True)\n",
    "                if len(j)>0:\n",
    "                    web_list.append(\"https://www.ptt.cc/\"+j[0][\"href\"])\n",
    "\n",
    "        else: return \"something wrong about ptt stock %s.\" %url\n",
    "\n",
    "        for j in web_list:\n",
    "            r2 = requests.get(j, headers=header)\n",
    "            if r2.status_code == 200:\n",
    "\n",
    "                soup2 = BeautifulSoup(r2.text, \"html.parser\")\n",
    "                soup2.title.string.split(\"-\")[0]\n",
    "\n",
    "                text = soup2.find(id=\"main-container\").text.split(\"--\")\n",
    "                pre_text = text[0].split('\\n')\n",
    "\n",
    "                push_text= []\n",
    "                for i in soup2.find_all(\"div\", class_=\"push\"):\n",
    "                    push_text.append(i.text)\n",
    "                \n",
    "                s = soup2.title.string.split(\"-\")[0]\n",
    "\n",
    "                with open(os.path.join(\"news/ptt/\", repr(s).replace(\"\\\\\",\"\").replace(\"/\",\"\").replace(\" \",\"\")+\".txt\"), \"w\") as f:\n",
    "                    f.write(\"\\n\".join(pre_text[1:]))\n",
    "                    f.write(\"\\n\".join(push_text))\n",
    "\n",
    "            else: return \"th post %s has something wrong\" %j\n",
    "    \n",
    "    def udn(self, url):\n",
    "        header = self.__dict__\n",
    "        r = requests.get(url, headers=header)\n",
    "\n",
    "        if r.status_code == 200:\n",
    "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "            \n",
    "            web_list = []\n",
    "            for i in soup.find_all(\"div\", class_=\"story__content\"):\n",
    "                j = i.find_all(\"a\", href=True)\n",
    "                web_list.append(j[0][\"href\"])\n",
    "\n",
    "        else: return \"something wrong about udn %s.\" %url\n",
    "\n",
    "        for j in web_list:\n",
    "            r2 = requests.get(j, headers=header)\n",
    "            if r2.status_code == 200:\n",
    "\n",
    "                soup = BeautifulSoup(r2.text, \"html.parser\")\n",
    "\n",
    "                timing = soup.find(\"time\",class_=\"article-body__time\")\n",
    "                if timing is not None:\n",
    "                    \n",
    "                    timing = timing.text\n",
    "                    title = soup.find(id=\"story_art_title\").text\n",
    "                    body = soup.find(\"section\",class_=\"article-body__editor\").text\n",
    "\n",
    "                    name = repr(title).replace(\"\\\\\",\"\").replace(\"/\",\"\").replace(\" \",\"\")\n",
    "\n",
    "                    with open(os.path.join(\"news/udn/\", name+\".txt\"), \"w\") as f:\n",
    "                        f.write(title)\n",
    "                        f.write('\\n')\n",
    "                        f.write(timing)\n",
    "                        f.write(body)\n",
    "\n",
    "            else: return \"th post %s has something wrong\" %j\n",
    "\n",
    "    def digitimes(self, url, page=5, **kwargs):\n",
    "        header = self.__dict__\n",
    "\n",
    "        web_list = []\n",
    "        for i in range(page+1):\n",
    "            if \"auth\" in kwargs.keys(): \n",
    "                auth = kwargs[\"auth\"]\n",
    "            else: auth = None\n",
    "            r = requests.post(url, \n",
    "                            headers=header,\n",
    "                            params= {\"page\":[i]})\n",
    "            if r.status_code == 200:\n",
    "                soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "                text = soup.find_all(\"div\",class_=\"subject_area\")\n",
    "                if text is not None:\n",
    "                    for j in text:\n",
    "                        web_list.append(\"https://www.digitimes.com.tw/\"+(j.find(\"a\").attrs[\"href\"]))\n",
    "                else: return \"something wrong about digitimes %s.\" %url\n",
    "        \n",
    "        for k in web_list:\n",
    "            r2 = requests.get(k, headers=header, auth=auth)\n",
    "            if r2.status_code == 200:\n",
    "                soup = BeautifulSoup(r2.text, \"html.parser\")\n",
    "\n",
    "                title = soup.find(\"h1\").text\n",
    "                title = repr(title).replace(\"\\\\\",\"\").replace(\"/\",\"\").replace(\" \",\"\")\n",
    "\n",
    "                with open(os.path.join(\"news/digitimes/\", title+\".txt\"), \"w\") as f:\n",
    "                    f.write(title.replace(\"'\",\"\"))\n",
    "                    f.write(\"\\n\")\n",
    "                    f.write(soup.find(\"time\").text)\n",
    "                    f.write(\"\\n\")\n",
    "                    for i in soup.find_all(\"p\", class_=\"main_p\"):\n",
    "                        k = repr(i.text).replace(r\"\\n\",\"\").replace(r\"\\r\",\"\").replace(r\"\\t\",\"\")\n",
    "                        f.write(k.replace(\"'\",\"\"))\n",
    "                        f.write(\"\\n\")\n",
    "            else: return \"th post %s has something wrong\" %k\n",
    "    \n",
    "    def finace(self, url, co_id, year, dtype=\"AI1\"):\n",
    "        param = {\"id\":\"\", \"key\":\"\", \"step\":1,\"co_id\":co_id, \"year\":year, \"seamon\":\"\", \"mtype\":\"A\", \"dtype\":dtype}\n",
    "\n",
    "        r = requests.post(url, params=param)\n",
    "        if r.status_code == 200:\n",
    "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "            name = soup.find_all(\"a\", href=True)\n",
    "\n",
    "        else: return print(\"something wrong about this web %s.\" %co_id)\n",
    "\n",
    "        if name[0].text != \"\":\n",
    "            for j in name:\n",
    "                param2 = {\"step\":9, \"kind\":\"A\", \"co_id\":co_id, \"filename\":j.text}\n",
    "                r2 = requests.post(url, params=param2)\n",
    "\n",
    "                if r2.status_code == 200:\n",
    "                    soup2 = BeautifulSoup(r2.text, \"html.parser\")\n",
    "                    link = soup2.find(\"a\", href=True)\n",
    "\n",
    "                    response = requests.get(\"https://doc.twse.com.tw/\"+link[\"href\"])\n",
    "                    if response.status_code == 200:\n",
    "                        with open(\"news/finance/\"+j.text, \"wb\") as f:\n",
    "                            f.write(response.content)\n",
    "                    else: return print(\"something wrong about this finance report %s.\" %\"https://doc.twse.com.tw/\"+link[\"href\"])\n",
    "                else: return print(\"something wrong about this download page %s.\" %j.text)\n",
    "        \n",
    "        else:\n",
    "            param2 = {\"step\":1, \"dtype\":dtype, \"mtype\":\"A\", \"co_id\":co_id, \"check2858\":\"Y\", \"year\":year}\n",
    "            r2 = requests.post(\"https://doc.twse.com.tw/server-java/t57sb01\", params=param2)\n",
    "            if r2.status_code == 200:\n",
    "                soup2 = BeautifulSoup(r2.text, \"html.parser\")\n",
    "                name = soup2.find_all(\"a\", href=True)\n",
    "\n",
    "            for j in name:\n",
    "                param3 = {\"step\":9, \"kind\":\"A\", \"co_id\":co_id, \"filename\":j.text}\n",
    "                r3 = requests.post(url, params=param3)\n",
    "\n",
    "                if r3.status_code == 200:\n",
    "                    soup3 = BeautifulSoup(r3.text, \"html.parser\")\n",
    "                    link = soup3.find(\"a\", href=True)\n",
    "\n",
    "                    response = requests.get(\"https://doc.twse.com.tw/\"+link[\"href\"])\n",
    "                    if response.status_code == 200:\n",
    "                        with open(\"news/finance/\"+j.text, \"wb\") as f:\n",
    "                            f.write(response.content)\n",
    "                    else: return print(\"something wrong about this finance report %s.\" %\"https://doc.twse.com.tw/\"+link[\"href\"])\n",
    "                else: return print(\"something wrong about this download page %s.\" %j.text)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the header for crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "cookie = \"uuid_tt_dd=10_20564905260-1703225841522-750867; c_first_ref=www.google.com; c_segment=3; c_adb=1; dc_sid=df9d26e5f60c9796335d2b2bdc46e0aa; hide_login=1; SidecHatdocDescBoxNum=true; creative_btn_mp=3; dc_session_id=10_1704181968889.661952; SESSION=ee7d1139-efc1-4491-8412-ffed93215f66; c_first_page=https%3A//blog.csdn.net/yinjun3215/article/details/108477055; c_dsid=11_1704184443684.220868; c_pref=https%3A//www.google.com/; c_ref=https%3A//blog.csdn.net/yinjun3215/article/details/108477055; c_utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-102261567-blog-108477055.235%5Ev40%5Epc_relevant_anti_t3; c_utm_relevant_index=2; c_page_id=default; log_Id_pv=19; loginbox_strategy=%7B%22taskId%22%3A308%2C%22abCheckTime%22%3A1704163911128%2C%22version%22%3A%22exp1%22%2C%22blog-threeH-dialogtipShowTimes%22%3A8%2C%22blog-threeH-dialog%22%3A1704182063207%7D; log_Id_view=477; log_Id_click=7; dc_tos=s6mm2j\"\n",
    "x = dict({\"User-Agent\":user_agent, \"Cookie\":cookie})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = crawl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6822\n"
     ]
    }
   ],
   "source": [
    "for k in range(6822,6823+1):\n",
    "    ptt_path = \"https://www.ptt.cc/bbs/Stock/index\"+str(k)+\".html\"\n",
    "    test.ptt(url=ptt_path)\n",
    "    if (k%3 == 0):\n",
    "        print(k)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    ptt_path = \"https://money.udn.com/rank/ajax_newest/1001/0/\"+str(k)\n",
    "    test.udn(url=ptt_path)\n",
    "    if (k%2 == 0):\n",
    "        print(k)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "cookie = \"vid=3421667e87765c5f; promotype=+; MyPwd=Br3%60ZV%7B4GJ0L48X27ZQHP0E5KN6B3UZ1HF3D1NL0PQIYV3CF3YOWL3L; RememberMyPwd=Y; MyName%5Fcn=; ASPSESSIONIDQURSQTSD=JIPDJCCCDDINKEBEFJLINEKJ; ASPSESSIONIDSUSCACAR=MAAPBGCCAGJCACCDLPADJJAK; ASPSESSIONIDAWQTBADA=EEDKNMBAAJGCCGFJFOPLKAJG; autorefresh=Y; ASPSESSIONIDCURQDBDA=CNDEFOGBJKKDIHJBHAFFMOPO; ASPSESSIONIDSERTTRRQ=DLMONBHBPNGNLNJCNMAHJOKF; ASPSESSIONIDAWSSABDA=OJDILHNBPHBHLECCOGGJIFPL; ASPSESSIONIDSEQRSTRQ=BBMMHJNBGPGFMKNELMDOKKBF; ASPSESSIONIDAWTSDCBB=PLLDHAICPDMBDKLMPHPOBCJH; ASPSESSIONIDSEQRRSQR=LPJCECICMPIHNHBOINLFOAAL; weblogIP=122A147A142A30; ASPSESSIONIDCWRQDBCB=HLGLMCGBINDIOLEFLLHLOCGB; ASPSESSIONIDQGSRTTRR=HCHOBPACIIOKDBMPNMKCHGLP; mem%5Fpro=N; justLogout=Y; ASPSESSIONIDSGTSQSRR=BLAGLGHCMGDFOOMNOFNDEJOE; MyName=%E9%BB%83%E9%9D%96%E5%87%B1; LEADtservice=%2CLEA%2CASC%2CCVC; LEAright=Y; CVC%5FEmail=james%2Ejk%2Ehuang%40foxconn%2Ecom; CVC%5FUserid=XAA45006; MemSID=661347451; ASC%5FUserid=XAA45006; yUID=james%2Ejk%2Ehuang%40foxconn%2Ecom; CVC%5FMemberid=XAB25034; MemberIDPDF=XAB25034; SSLUID=XAA45006; occupation=1; ASC%5FEmail=james%2Ejk%2Ehuang%40foxconn%2Ecom; LEAMyName=%E9%BB%83%E9%9D%96%E5%87%B1; LEAyUID=james%2Ejk%2Ehuang%40foxconn%2Ecom; LEAMemberID=XAB25034; CVC%5FMyName=%E9%BB%83%E9%9D%96%E5%87%B1; DownMYID=james%2Ejk%2Ehuang%40foxconn%2Ecom; MyID=BkN%6029nZXVd4UB3tQH3SP%2DP89VKTk7235X77jOYEYLXNZ%2FBKJ6G46OYgUK1GV3PXCAvPMLSK4XOOT7%60ZHH6FE7MFQKZoEQV9AAYZ8D3LPf9X1OG2L9DPVAXCA9HI5DP772E779EKeBJY4DIYP6QIK8TN5pMOFY072U9YJEWEDO2w4L4QG0TWARYE53GTK9dYFKY2TLPRCIN26ZM4A1nD8ZX3HH23AQK1FPOYANMoX6UQR6DR41CFMCA9G1QO8m15BRA3NKWKP8KN99FG53S5%2FS8KIZYIF5Z4UIGFWNBABHNUb28O66SJA08R9HRLTVOXXLR7QpEURWPN9XDTIVECKE7YQWZ8EVClDKV6QZ5UDE4IT0OT6CXTF43Z4O; DownUID=XAA45006; ASC%5FMyName=%E9%BB%83%E9%9D%96%E5%87%B1; ASC%5FMemberid=XAB25034; UserIDPDF=XAA45006; DownMemID=XAB25034; CVCsid=661347451; sDownImage=CAR%2DY%2CSTN%2DY%2CICM%2DY%2CICD%2DY%2CEVF%2DY%2CSVR%2DY%2CCMP%2DY%2CCSE%2DY%2CIOT%2DY%2CSMG%2DY%2CBWC%2DY%2CSML%2DY%2CSMF%2DY%2CATC%2DY%2CAAI%2DY%2CDHM%2DY%2CMCN%2DY%2CGNT%2DY%2CAIP%2DY%2CAIR%2DY%2C5GF%2DY%2CPCE%2DY%2C; sDataView=CAR%2DY%2CSTN%2DN%2CICM%2DY%2CICD%2DY%2CEVF%2DN%2CSVR%2DY%2CCMP%2DY%2CCSE%2DN%2CIOT%2DN%2CSMG%2DN%2CBWC%2DN%2CSML%2DN%2CSMF%2DY%2CATC%2DN%2CAAI%2DN%2CDHM%2DN%2CMCN%2DY%2CGNT%2DN%2CAIP%2DN%2CAIR%2DN%2C5GF%2DN%2CPCE%2DN%2C; sDownRight=CAR%2DN%2CSTN%2DN%2CICM%2DN%2CICD%2DN%2CEVF%2DN%2CSVR%2DN%2CCMP%2DN%2CCSE%2DN%2CIOT%2DN%2CSMG%2DN%2CBWC%2DN%2CSML%2DN%2CSMF%2DN%2CATC%2DN%2CAAI%2DN%2CDHM%2DN%2CMCN%2DN%2CGNT%2DN%2CAIP%2DN%2CAIR%2DN%2C5GF%2DN%2CPCE%2DN%2C; sDataFile=CAR%2DY%2CSTN%2DN%2CICM%2DY%2CICD%2DY%2CEVF%2DN%2CSVR%2DY%2CCMP%2DY%2CCSE%2DN%2CIOT%2DN%2CSMG%2DN%2CBWC%2DN%2CSML%2DN%2CSMF%2DY%2CATC%2DN%2CAAI%2DN%2CDHM%2DN%2CMCN%2DY%2CGNT%2DN%2CAIP%2DN%2CAIR%2DN%2C5GF%2DN%2CPCE%2DN%2C; sRptRight=%2CCAR%2CSTN%2CICM%2CICD%2CEVF%2CSVR%2CCMP%2CCSE%2CIOT%2CSMG%2CBWC%2CSML%2CSMF%2CATC%2CAAI%2CDHM%2CMCN%2CGNT%2CAIP%2CAIR%2C5GF%2CPCE; sShow=Y; ASPSESSIONIDCWTQCDAA=AEJOPEHCPGMCHDGOENIELCIG; AWSALBTG=/uORw842ciPxp12V2yJY6waw3E16a9wX/UcvlC7YbKEe7AHJ0w/U/b6/UTaa6rs5pSzNF51c0ocf2oHoIOB+8HsUoTSU1Ew6APaTAtj2MEplffb2OOIH2qrqW8r2iDLzo9WAvgFLmJ/JITJRj2exDGeuoWh5R000r3JfOJZt+onK55cLmTA=; AWSALBTGCORS=/uORw842ciPxp12V2yJY6waw3E16a9wX/UcvlC7YbKEe7AHJ0w/U/b6/UTaa6rs5pSzNF51c0ocf2oHoIOB+8HsUoTSU1Ew6APaTAtj2MEplffb2OOIH2qrqW8r2iDLzo9WAvgFLmJ/JITJRj2exDGeuoWh5R000r3JfOJZt+onK55cLmTA=; AWSALB=KGNQWtiqS1l0h1g/+OMPtacS7IEGs2GGILLW7NcOfuubgyLYVG0nlZc18fDniScgJpKqNwk/wtSrwsSx6E0631LCflaSIpI3p8bij12XGPGI+JuB/9GL6Ywy3Pj6; AWSALBCORS=KGNQWtiqS1l0h1g/+OMPtacS7IEGs2GGILLW7NcOfuubgyLYVG0nlZc18fDniScgJpKqNwk/wtSrwsSx6E0631LCflaSIpI3p8bij12XGPGI+JuB/9GL6Ywy3Pj6\"\n",
    "origin = \"https://www.digitimes.com.tw\"\n",
    "referer = \"https://www.digitimes.com.tw/tech/dt/allnewslist.asp?CnlID=99\"\n",
    "content_type = \"application/x-www-form-urlencoded; charset=UTF-8\"\n",
    "x = dict({\"User-Agent\":user_agent, \"Cookie\":cookie,\"Orgin\":origin ,\"Referer\":referer, \"Content-Type\":content_type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.digitimes(url=\"https://www.digitimes.com.tw/tech/ajax/newslist_ajax.asp\", \n",
    "               auth=(\"james.jk.huang@foxconn.com\", \"Br3`ZV{4GJ0L48X27ZQHP0E5KN6B3UZ1HF3D1NL0PQIYV3CF3YOWL3L\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', BadStatusLine('<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\\r\\n'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadStatusLine\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-個人/github/tapioca/news-robot/lib/python3.9/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-個人/github/tapioca/news-robot/lib/python3.9/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-個人/github/tapioca/news-robot/lib/python3.9/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1345\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1345\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1346\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:307\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 307\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    308\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:289\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mraise\u001b[39;00m BadStatusLine(line)\n\u001b[1;32m    291\u001b[0m \u001b[39m# The status code is a three-digit number\u001b[39;00m\n",
      "\u001b[0;31mBadStatusLine\u001b[0m: <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\r\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-個人/github/tapioca/news-robot/lib/python3.9/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-個人/github/tapioca/news-robot/lib/python3.9/site-packages/urllib3/connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    842\u001b[0m     new_e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, new_e)\n\u001b[0;32m--> 844\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    845\u001b[0m     method, url, error\u001b[39m=\u001b[39;49mnew_e, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    846\u001b[0m )\n\u001b[1;32m    847\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-個人/github/tapioca/news-robot/lib/python3.9/site-packages/urllib3/util/retry.py:470\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mraise\u001b[39;00m reraise(\u001b[39mtype\u001b[39;49m(error), error, _stacktrace)\n\u001b[1;32m    471\u001b[0m \u001b[39melif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-個人/github/tapioca/news-robot/lib/python3.9/site-packages/urllib3/util/util.py:38\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m     39\u001b[0m \u001b[39mraise\u001b[39;00m value\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-個人/github/tapioca/news-robot/lib/python3.9/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-個人/github/tapioca/news-robot/lib/python3.9/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-個人/github/tapioca/news-robot/lib/python3.9/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1345\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1345\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1346\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:307\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 307\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    308\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:289\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mraise\u001b[39;00m BadStatusLine(line)\n\u001b[1;32m    291\u001b[0m \u001b[39m# The status code is a three-digit number\u001b[39;00m\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', BadStatusLine('<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\\r\\n'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m#3711\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m [\u001b[39m5880\u001b[39m]:\n\u001b[0;32m----> 8\u001b[0m     test\u001b[39m.\u001b[39;49mfinace(url\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mhttps://doc.twse.com.tw/server-java/t57sb01\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m                 co_id\u001b[39m=\u001b[39;49mi, year\u001b[39m=\u001b[39;49m\u001b[39m112\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m15\u001b[39m)\n",
      "Cell \u001b[0;32mIn[80], line 154\u001b[0m, in \u001b[0;36mcrawl.finace\u001b[0;34m(self, url, co_id, year, dtype)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m name:\n\u001b[1;32m    153\u001b[0m     param3 \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m9\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mA\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mco_id\u001b[39m\u001b[39m\"\u001b[39m:co_id, \u001b[39m\"\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m\"\u001b[39m:j\u001b[39m.\u001b[39mtext}\n\u001b[0;32m--> 154\u001b[0m     r3 \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mpost(url, params\u001b[39m=\u001b[39;49mparam3)\n\u001b[1;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m r3\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m    157\u001b[0m         soup3 \u001b[39m=\u001b[39m BeautifulSoup(r3\u001b[39m.\u001b[39mtext, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-個人/github/tapioca/news-robot/lib/python3.9/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-個人/github/tapioca/news-robot/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-個人/github/tapioca/news-robot/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-個人/github/tapioca/news-robot/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-個人/github/tapioca/news-robot/lib/python3.9/site-packages/requests/adapters.py:501\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    503\u001b[0m \u001b[39mexcept\u001b[39;00m MaxRetryError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    504\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[1;32m    505\u001b[0m         \u001b[39m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[0;31mConnectionError\u001b[0m: ('Connection aborted.', BadStatusLine('<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\\r\\n'))"
     ]
    }
   ],
   "source": [
    "company_code = [2330, 2454, 2317, 2412, 2382, 2881, 2308, 6505, 2882, 2303, 3711, 2886, 2891, 1303, 1301, 2002, 1216, 2884, 2207, 5880, 3008, 2892, 3045, 1326, 2357, 2885, 6669, \n",
    "                2395, 3034, 5871, 2880, 2603, 2345, 3231, 4904, 2912, 2301, 3037, 1101, 2327, 2890, 2379, 2408, 3661, 3443, 4938, 5876, 2887, 2883, 1590, 2801, 6415, 2356, 2609,\n",
    "                2324, 9910, 2377, 2618, 2376, 1402, 2353, 8046, 1605, 2615, 1476, 6509, 1102, 2105, 2409, 2888, 3702, 2385, 2474, 2610, 3481, 3017, 2344, 2383, 5269, 8454]\n",
    "\n",
    "#3711\n",
    "\n",
    "for i in [5880]:\n",
    "    test.finace(url=\"https://doc.twse.com.tw/server-java/t57sb01\",\n",
    "                co_id=i, year=112)\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news-robot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
