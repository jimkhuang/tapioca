{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import requests\n",
    "import sqlite3\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animal():\n",
    "    def __init__(self, vars ,**kwargs):\n",
    "        self.__dict__.update(vars, **kwargs)\n",
    "\n",
    "class crawl(Animal):\n",
    "\n",
    "    def ptt(self, url):\n",
    "        header = self.__dict__\n",
    "        r = requests.get(url, headers=header)\n",
    "\n",
    "        if r.status_code == 200:\n",
    "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "       \n",
    "            web_list = []\n",
    "            for i in soup.find_all(\"div\", class_='r-ent'):\n",
    "                j = i.find_all(\"a\", href=True)\n",
    "                if len(j)>0:\n",
    "                    web_list.append(\"https://www.ptt.cc/\"+j[0][\"href\"])\n",
    "\n",
    "        else: return \"something wrong about ptt stock.\"\n",
    "\n",
    "        for j in web_list:\n",
    "            r2 = requests.get(j, headers=header)\n",
    "            if r2.status_code == 200:\n",
    "\n",
    "                soup2 = BeautifulSoup(r2.text, \"html.parser\")\n",
    "                soup2.title.string.split(\"-\")[0]\n",
    "\n",
    "                text = soup2.find(id=\"main-container\").text.split(\"--\")\n",
    "                pre_text = text[0].split('\\n')\n",
    "\n",
    "                push_text= []\n",
    "                for i in soup2.find_all(\"div\", class_=\"push\"):\n",
    "                    push_text.append(i.text)\n",
    "\n",
    "                with open(os.path.join(\"news/ptt/\", soup2.title.string.split(\"-\")[0].replace(r'/',\"\")+\".txt\"), \"w\") as f:\n",
    "                    f.write(\"\\n\".join(pre_text[1:]))\n",
    "                    f.write(\"\\n\".join(push_text))\n",
    "\n",
    "            else: return \"th post %s has something wrong\" %j\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "cookie = \"uuid_tt_dd=10_20564905260-1703225841522-750867; c_first_ref=www.google.com; c_segment=3; c_adb=1; dc_sid=df9d26e5f60c9796335d2b2bdc46e0aa; hide_login=1; SidecHatdocDescBoxNum=true; creative_btn_mp=3; dc_session_id=10_1704181968889.661952; SESSION=ee7d1139-efc1-4491-8412-ffed93215f66; c_first_page=https%3A//blog.csdn.net/yinjun3215/article/details/108477055; c_dsid=11_1704184443684.220868; c_pref=https%3A//www.google.com/; c_ref=https%3A//blog.csdn.net/yinjun3215/article/details/108477055; c_utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-102261567-blog-108477055.235%5Ev40%5Epc_relevant_anti_t3; c_utm_relevant_index=2; c_page_id=default; log_Id_pv=19; loginbox_strategy=%7B%22taskId%22%3A308%2C%22abCheckTime%22%3A1704163911128%2C%22version%22%3A%22exp1%22%2C%22blog-threeH-dialogtipShowTimes%22%3A8%2C%22blog-threeH-dialog%22%3A1704182063207%7D; log_Id_view=477; log_Id_click=7; dc_tos=s6mm2j\"\n",
    "x = dict({\"User-Agent\":user_agent, \"Cookie\":cookie})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = crawl(x)\n",
    "test.ptt(url=\"https://www.ptt.cc/bbs/Stock/index6815.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(r_ptt[0], headers=x)\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "soup.title.string.split(\"-\")[0]\n",
    "\n",
    "text = soup.find(id=\"main-container\").text.split(\"--\")\n",
    "pre_text = text[0].split('\\n')\n",
    "\n",
    "push_text= []\n",
    "for i in soup.find_all(\"div\", class_=\"push\"):\n",
    "    push_text.append(i.text)\n",
    "\n",
    "with open(os.path.join(\"news/ptt/\", soup.title.string.split(\"-\")[0]+\".txt\"), \"w\") as f:\n",
    "    f.write(\"\\n\".join(pre_text[1:]))\n",
    "    f.write(\"\\n\".join(push_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newsptt[閒聊] 20240102 盤中閒聊 .txt'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'news/ptt/[閒聊] 2024/01/02 盤中閒聊 .txt'.replace(r'/',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news-robot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
